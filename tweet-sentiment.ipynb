{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Сентимент-анализ базы твитов RuTweetCorp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузим и изучим данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114911, 12)\n",
      "(111923, 12)\n"
     ]
    }
   ],
   "source": [
    "columns = ['id', 'tdate', 'tmane', 'ttext', 'ttype', 'trep', 'trtw', 'tfav', 'tstcount', 'tfol', 'tfrien', 'listcount']\n",
    "pos = pd.read_csv('positive.csv', sep=';', names=columns)\n",
    "print(pos.shape)\n",
    "neg = pd.read_csv('negative.csv', sep=';', names=columns)\n",
    "print(neg.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размер выборок положительного и отрицательного окраса почти одинаков, нам не нужно будет что-то с этим делать.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, нет ли в выборках дупликатов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110396, 107044)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos['ttext'].value_counts()), len(neg['ttext'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть несколько тысяч в каждой выборке, избавимся от них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110396, 12)\n",
      "(107044, 12)\n"
     ]
    }
   ],
   "source": [
    "pos = pos.drop_duplicates(subset=['ttext'])\n",
    "print(pos.shape)\n",
    "neg = neg.drop_duplicates(subset=['ttext'])\n",
    "print(neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим простейшую модель на связке \"мешка слов\" и логистической регрессии, которая будет нашим baseline'ом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7398756959058405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(pos['ttext'].append(neg['ttext']))\n",
    "y = pos['ttype'].append(neg['ttype'])\n",
    "clf=LogisticRegression(solver='lbfgs')\n",
    "scores = cross_val_score(clf, X, y, cv=5, scoring='f1_macro')\n",
    "\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, наш baseline -- 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные поближе. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tdate</th>\n",
       "      <th>tmane</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>trep</th>\n",
       "      <th>trtw</th>\n",
       "      <th>tfav</th>\n",
       "      <th>tstcount</th>\n",
       "      <th>tfol</th>\n",
       "      <th>tfrien</th>\n",
       "      <th>listcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>408906692374446080</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>pleease_shut_up</td>\n",
       "      <td>@first_timee хоть я и школота, но поверь, у на...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7569</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>408906692693221377</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>alinakirpicheva</td>\n",
       "      <td>Да, все-таки он немного похож на него. Но мой ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11825</td>\n",
       "      <td>59</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>408906695083954177</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>EvgeshaRe</td>\n",
       "      <td>RT @KatiaCheh: Ну ты идиотка) я испугалась за ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1273</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>408906695356973056</td>\n",
       "      <td>1386325927</td>\n",
       "      <td>ikonnikova_21</td>\n",
       "      <td>RT @digger2912: \"Кто то в углу сидит и погибае...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1549</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>408906761416867842</td>\n",
       "      <td>1386325943</td>\n",
       "      <td>JumpyAlex</td>\n",
       "      <td>@irina_dyshkant Вот что значит страшилка :D\\nН...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>597</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id       tdate            tmane  \\\n",
       "0  408906692374446080  1386325927  pleease_shut_up   \n",
       "1  408906692693221377  1386325927  alinakirpicheva   \n",
       "2  408906695083954177  1386325927        EvgeshaRe   \n",
       "3  408906695356973056  1386325927    ikonnikova_21   \n",
       "4  408906761416867842  1386325943        JumpyAlex   \n",
       "\n",
       "                                               ttext  ttype  trep  trtw  tfav  \\\n",
       "0  @first_timee хоть я и школота, но поверь, у на...      1     0     0     0   \n",
       "1  Да, все-таки он немного похож на него. Но мой ...      1     0     0     0   \n",
       "2  RT @KatiaCheh: Ну ты идиотка) я испугалась за ...      1     0     1     0   \n",
       "3  RT @digger2912: \"Кто то в углу сидит и погибае...      1     0     1     0   \n",
       "4  @irina_dyshkant Вот что значит страшилка :D\\nН...      1     0     0     0   \n",
       "\n",
       "   tstcount  tfol  tfrien  listcount  \n",
       "0      7569    62      61          0  \n",
       "1     11825    59      31          2  \n",
       "2      1273    26      27          0  \n",
       "3      1549    19      17          0  \n",
       "4       597    16      23          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо удалить все тегирования пользователей, хештеги, ретвиты, ссылки и системные символы.\n",
    "Радостные смайлы я заменю на признак good_flag, а расстроенные на bad_flag. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(documents):\n",
    "    \"\"\"\n",
    "    Replaces urls, hashtags and usernames with spaces.\n",
    "    Replaces smiles with special tags.\n",
    "    :param documents: list: of str\n",
    "    :returns docs: list: of str\n",
    "    \"\"\"\n",
    "    docs = list()\n",
    "\n",
    "    for doc in documents:\n",
    "        text = re.sub(\"(@\\w+)|(#\\w+)\", \" \", doc.lower())\n",
    "    \n",
    "        text = re.sub(\"\\n\", \" \", text)\n",
    "        text = re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", text)\n",
    "        text = re.sub(\"rt \", \" \", text)\n",
    "        text = re.sub(\" rt \", \" \", text)\n",
    "        text = re.sub(\":\\(\", \" bad_flag \", text)\n",
    "        text = re.sub(\"\\(\\(+\", \" bad_flag \", text)\n",
    "        text = re.sub(\"99+\", \" bad_flag \", text)\n",
    "        text = re.sub(\"0_0\", \" bad_flag \", text)\n",
    "        text = re.sub(\"o_o\", \" bad_flag \", text)\n",
    "        text = re.sub(\"о_о\", \" bad_flag \", text)\n",
    "        text = re.sub(\":-\\(\", \" bad_flag \", text)\n",
    "        text = re.sub(\"=\\(\", \" bad_flag \", text)\n",
    "        text = re.sub(\" \\(\", \" bad_flag \", text)\n",
    "#         text = re.sub(\"\\(\", \" bad_flag \", text)\n",
    "        text = re.sub(\";\\)\", \" good_flag \", text)\n",
    "        text = re.sub(\":d+\", \" good_flag \", text)\n",
    "        text = re.sub(\"\\=\\)+\", \" good_flag \", text)\n",
    "        text = re.sub(\"\\)+\", \" good_flag \", text)\n",
    "        text = re.sub(\":\\)\", \" good_flag \", text)\n",
    "        \n",
    "        text = re.sub(r'[^\\w\\s]','' , text)\n",
    "        \n",
    "\n",
    "        text = text.strip()\n",
    "        docs.append(text)\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def get_features_by_weights(vectorizer, model, number_of_features=10):\n",
    "    ## get feature weights\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs = model.coef_[0]\n",
    "#     print(np.argsort(coefs))\n",
    "    top_features_pos = np.argsort(coefs)[-number_of_features:]\n",
    "    top_features_neg = np.argsort(coefs)[:number_of_features]\n",
    "    features = [(feature_names[pos_feature_place], feature_names[neg_feature_place])  for pos_feature_place, neg_feature_place in zip(top_features_pos[::-1], top_features_neg)]\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos['ttext'] = cleaner(pos['ttext'])\n",
    "neg['ttext'] = cleaner(neg['ttext'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107481, 12)\n",
      "(104008, 12)\n"
     ]
    }
   ],
   "source": [
    "pos = pos.drop_duplicates(subset=['ttext'])\n",
    "print(pos.shape)\n",
    "neg = neg.drop_duplicates(subset=['ttext'])\n",
    "print(neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(pos['ttext'].append(neg['ttext']))\n",
    "y = pos['ttype'].append(neg['ttype'])\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "scores = cross_val_score(clf, X, y, cv=3, scoring='f1_macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9845993440438895"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат намного лучше baseline'а. Посмотрим для интереса на feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good_flag', 'bad_flag'),\n",
       " ('gtd', 'сожалению'),\n",
       " ('обожаю', 'боюсь'),\n",
       " ('поржали', 'обидно'),\n",
       " ('скажу', 'жалко'),\n",
       " ('приятно', 'походу'),\n",
       " ('рада', 'печально'),\n",
       " ('любимая', 'печаль'),\n",
       " ('ddd', 'стыдно'),\n",
       " ('люблю', 'увы')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features_by_weights(vectorizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что смайл является самым важным параметром и в отрицательных и в положительных сообщениях. Изучим это чуть подробнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([pos[['ttext', 'ttype']], neg[['ttext', 'ttype']]])\n",
    "# data_train.head()\n",
    "data_train.rename(columns={\"ttext\": \"body\"}, inplace = True)\n",
    "data_train.rename(columns={\"ttype\": \"label\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество записей, в которых нет смайла: 0.17232574743840104\n"
     ]
    }
   ],
   "source": [
    "print(\"Количество записей, в которых нет смайла:\", data_train.loc[(~data_train['body'].str.contains('good_flag')) & (~data_train['body'].str.contains('bad_flag'))].shape[0] / data_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что смайл присутствует в 83% твитов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на корреляцию наличия смайла и метки сентимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def what_smile(body):\n",
    "    if ('good_flag' in body) & ('bad_flag' in body):\n",
    "        return 0\n",
    "    elif 'good_flag' in body:\n",
    "        return 1\n",
    "    elif 'bad_flag' in body:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['what_smile'] = data_train['body'].apply(what_smile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>what_smile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>label</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.919745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>what_smile</td>\n",
       "      <td>0.919745</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label  what_smile\n",
       "label       1.000000    0.919745\n",
       "what_smile  0.919745    1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляция почти 90%, наличие смайла очень сильный признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что ж, самое время пройтись по сетке параметров и найти лучшую модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = [    \n",
    "    {\n",
    "        'vect': [TfidfVectorizer()],\n",
    "        'vect__max_df': (0.25, 0.5, 0.75),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    },\n",
    "    {\n",
    "        'vect': [CountVectorizer()],\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000),\n",
    "        'vect__ngram_range': ((1, 1), (1, 2))\n",
    "#         'regr__alpha': np.logspace(-4, 1, 6),\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'clf': [SGDClassifier()],\n",
    "        'clf__max_iter': (20, 25),\n",
    "        'clf__alpha': (0.00001, 0.000001),\n",
    "        'clf__penalty': ('l2', 'elasticnet'),\n",
    "    },\n",
    "    {\n",
    "        'clf': [LogisticRegression()],\n",
    "        'clf__C': np.logspace(-3,3, 4),\n",
    "        'clf__penalty': ('l2', 'l2'),\n",
    "    },\n",
    "    {   'clf': [XGBClassifier(objective ='binary:logistic', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)],\n",
    "        'clf__min_child_weight': [0.5, 1],\n",
    "        'clf__gamma': [5, 10],\n",
    "        'clf__subsample': [0.7, 1.0],\n",
    "        'clf__colsample_bytree': [0.5, 1.0],\n",
    "        'clf__max_depth': [8, 12]\n",
    "        }\n",
    "\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'clf']\n",
      "parameters:\n",
      "[{'vect': [TfidfVectorizer()], 'vect__max_df': (0.25, 0.5, 0.75), 'vect__ngram_range': ((1, 1), (1, 2))}, {'vect': [CountVectorizer()], 'vect__max_df': (0.5, 0.75, 1.0), 'vect__max_features': (None, 5000, 10000), 'vect__ngram_range': ((1, 1), (1, 2))}, {'clf': [SGDClassifier()], 'clf__max_iter': (20, 25), 'clf__alpha': (1e-05, 1e-06), 'clf__penalty': ('l2', 'elasticnet')}, {'clf': [LogisticRegression()], 'clf__C': array([1.e-03, 1.e-01, 1.e+01, 1.e+03]), 'clf__penalty': ('l2', 'l2')}, {'clf': [XGBClassifier(alpha=10, colsample_bytree=0.3, max_depth=5, n_estimators=10)], 'clf__min_child_weight': [0.5, 1], 'clf__gamma': [5, 10], 'clf__subsample': [0.7, 1.0], 'clf__colsample_bytree': [0.5, 1.0], 'clf__max_depth': [8, 12]}]\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 12.6min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 51.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.984594\n",
      "Best parameters set:\n",
      "{'memory': None, 'steps': [('vect', CountVectorizer()), ('clf', SGDClassifier(alpha=1e-05, max_iter=25, penalty='elasticnet'))], 'verbose': False, 'vect': CountVectorizer(), 'clf': SGDClassifier(alpha=1e-05, max_iter=25, penalty='elasticnet'), 'vect__analyzer': 'word', 'vect__binary': False, 'vect__decode_error': 'strict', 'vect__dtype': <class 'numpy.int64'>, 'vect__encoding': 'utf-8', 'vect__input': 'content', 'vect__lowercase': True, 'vect__max_df': 1.0, 'vect__max_features': None, 'vect__min_df': 1, 'vect__ngram_range': (1, 1), 'vect__preprocessor': None, 'vect__stop_words': None, 'vect__strip_accents': None, 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vect__tokenizer': None, 'vect__vocabulary': None, 'clf__alpha': 1e-05, 'clf__average': False, 'clf__class_weight': None, 'clf__early_stopping': False, 'clf__epsilon': 0.1, 'clf__eta0': 0.0, 'clf__fit_intercept': True, 'clf__l1_ratio': 0.15, 'clf__learning_rate': 'optimal', 'clf__loss': 'hinge', 'clf__max_iter': 25, 'clf__n_iter_no_change': 5, 'clf__n_jobs': None, 'clf__penalty': 'elasticnet', 'clf__power_t': 0.5, 'clf__random_state': None, 'clf__shuffle': True, 'clf__tol': 0.001, 'clf__validation_fraction': 0.1, 'clf__verbose': 0, 'clf__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, n_jobs=-1, verbose=1, scoring=f1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "print(\"parameters:\")\n",
    "print(param_grid)\n",
    "grid_search.fit(data_train['body'], data_train['label'])\n",
    "\n",
    "print(\"Best score: %0.6f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, лучшая текущая модель дала нам f1-score: 0.984594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь дообучить какую-нибудь нейронную сеть, например fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext import train_supervised, load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "params = dict()\n",
    "params['epoch'] = [30, 40]\n",
    "params['lr'] = [1, 0.1]\n",
    "\n",
    "params['min_count'] = [5, 10]\n",
    "\n",
    "params['word_ngrams'] = [1, 2]\n",
    "params['dim'] = [100, 200]\n",
    "params['loss'] = ['softmax']\n",
    "\n",
    "model_results = pd.DataFrame(columns=['model', 'type', 'precision', 'recall', 'f1-score'])\n",
    "types = ['pos', 'neg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отформатируем данные для использования моделью FastText и разделим их для дальнейшей кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_classification_metrics(target_class, predicted_class):\n",
    "    result = metrics.classification_report(target_class, predicted_class, target_names=['pos', 'neg'], output_dict=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "df = data_train\n",
    "\n",
    "\n",
    "new_folds = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "folds = skf.get_n_splits(df['body'], df['label'])\n",
    "for train_index, test_index in skf.split(data_train['body'], data_train['label']):\n",
    "    new_folds.append([df.iloc[train_index], df.iloc[test_index]])\n",
    "\n",
    "# print(new_folds)\n",
    "\n",
    "folds = new_folds\n",
    "\n",
    "\n",
    "kfold_metrics = []\n",
    "\n",
    "#paths to write files in fasttext format\n",
    "train_path = 'data_train'\n",
    "test_path = 'data_test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ft_format(documents, labels, file_path):\n",
    "    \"\"\"\n",
    "    Converts and save a dataset to fasttext compliant training format.\n",
    "    \n",
    "    :param documents: list: of str\n",
    "    :param labels: list: of str/int\n",
    "    :file_path: str\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add mandatory \"__label__\" prefix to the labels as required by fasttext\n",
    "    labels = [\"__label__\"+str(label) for label in labels]\n",
    "    \n",
    "    # clean up documents\n",
    "    documents = cleaner(documents)\n",
    "    \n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as f:\n",
    "        for doc, label in zip(documents, labels):\n",
    "            f.write(label + \" \" + doc + \"\\n\")\n",
    "            \n",
    "    print(\"Output file with %d samples saved at location: %s\"%(len(labels), file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 211489 samples saved at location: data_train.txt\n"
     ]
    }
   ],
   "source": [
    "to_ft_format([x for x in data_train['body']], [x for x in data_train['label']], 'data_train.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, в conda нет GridSearch для FastText, поэтому просто переберём параметры вручную по нескольким фолдам, подготовленным ранее. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 1\n",
      "[{'pos': {'precision': 0.9808549170667203, 'recall': 0.9841649841361407, 'f1-score': 0.982507162704983, 'support': 34670}, 'neg': {'precision': 0.9846261551386166, 'recall': 0.9814106679320066, 'f1-score': 0.983015782042859, 'support': 35827}, 'accuracy': 0.9827652240520873, 'macro avg': {'precision': 0.9827405361026684, 'recall': 0.9827878260340737, 'f1-score': 0.982761472373921, 'support': 70497}, 'weighted avg': {'precision': 0.9827714829688414, 'recall': 0.9827652240520873, 'f1-score': 0.982765646115881, 'support': 70497}}, {'pos': {'precision': 0.983101105481345, 'recall': 0.9850010095474343, 'f1-score': 0.9840501404797924, 'support': 34669}, 'neg': {'precision': 0.9854586129753915, 'recall': 0.9836157088229548, 'f1-score': 0.9845362984899494, 'support': 35827}, 'accuracy': 0.984296981389015, 'macro avg': {'precision': 0.9842798592283682, 'recall': 0.9843083591851945, 'f1-score': 0.9842932194848709, 'support': 70496}, 'weighted avg': {'precision': 0.984299221984256, 'recall': 0.984296981389015, 'f1-score': 0.9842972124133758, 'support': 70496}}, {'pos': {'precision': 0.9792245751783821, 'recall': 0.9856644264328362, 'f1-score': 0.9824339476180892, 'support': 34669}, 'neg': {'precision': 0.9860389336779123, 'recall': 0.9797638652412984, 'f1-score': 0.9828913840898272, 'support': 35827}, 'accuracy': 0.9826656831593282, 'macro avg': {'precision': 0.9826317544281472, 'recall': 0.9827141458370674, 'f1-score': 0.9826626658539582, 'support': 70496}, 'weighted avg': {'precision': 0.982687722335138, 'recall': 0.9826656831593282, 'f1-score': 0.9826664228858059, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 2\n",
      "[{'pos': {'precision': 0.9801529756319486, 'recall': 0.9942601672916066, 'f1-score': 0.9871561734847292, 'support': 34670}, 'neg': {'precision': 0.9943670742753623, 'recall': 0.9805174868116225, 'f1-score': 0.9873937179397091, 'support': 35827}, 'accuracy': 0.987276054300183, 'macro avg': {'precision': 0.9872600249536554, 'recall': 0.9873888270516146, 'f1-score': 0.9872749457122192, 'support': 70497}, 'weighted avg': {'precision': 0.9873766661733558, 'recall': 0.987276054300183, 'f1-score': 0.9872768950074685, 'support': 70497}}, {'pos': {'precision': 0.9814704124327556, 'recall': 0.9946061322795581, 'f1-score': 0.9879946133348614, 'support': 34669}, 'neg': {'precision': 0.9947119871051664, 'recall': 0.9818293465821866, 'f1-score': 0.988228683803905, 'support': 35827}, 'accuracy': 0.9881128007262824, 'macro avg': {'precision': 0.988091199768961, 'recall': 0.9882177394308723, 'f1-score': 0.9881116485693833, 'support': 70496}, 'weighted avg': {'precision': 0.9881999558932137, 'recall': 0.9881128007262824, 'f1-score': 0.9881135710444396, 'support': 70496}}, {'pos': {'precision': 0.9780705482362941, 'recall': 0.9957310565635006, 'f1-score': 0.9868217940655196, 'support': 34669}, 'neg': {'precision': 0.9957955739893753, 'recall': 0.9783961816507104, 'f1-score': 0.9870192036943177, 'support': 35827}, 'accuracy': 0.9869212437585111, 'macro avg': {'precision': 0.9869330611128347, 'recall': 0.9870636191071055, 'f1-score': 0.9869204988799187, 'support': 70496}, 'weighted avg': {'precision': 0.9870786408607785, 'recall': 0.9869212437585111, 'f1-score': 0.9869221202509905, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 1\n",
      "[{'pos': {'precision': 0.9816577063508035, 'recall': 0.9848572252668013, 'f1-score': 0.9832548630008782, 'support': 34670}, 'neg': {'precision': 0.9852998823990592, 'recall': 0.9821922014123426, 'f1-score': 0.9837435875931284, 'support': 35827}, 'accuracy': 0.9835028440926564, 'macro avg': {'precision': 0.9834787943749314, 'recall': 0.9835247133395719, 'f1-score': 0.9834992252970033, 'support': 70497}, 'weighted avg': {'precision': 0.9835086821551761, 'recall': 0.9835028440926564, 'f1-score': 0.9835032357822242, 'support': 70497}}, {'pos': {'precision': 0.9823186658629697, 'recall': 0.9871354812656841, 'f1-score': 0.9847211831731599, 'support': 34669}, 'neg': {'precision': 0.9874919370670555, 'recall': 0.9828062634326067, 'f1-score': 0.9851435286217893, 'support': 35827}, 'accuracy': 0.9849353154788925, 'macro avg': {'precision': 0.9849053014650127, 'recall': 0.9849708723491454, 'f1-score': 0.9849323558974746, 'support': 70496}, 'weighted avg': {'precision': 0.9849477907413853, 'recall': 0.9849353154788925, 'f1-score': 0.9849358247186101, 'support': 70496}}, {'pos': {'precision': 0.9802457792580682, 'recall': 0.9847414116357552, 'f1-score': 0.9824884527389671, 'support': 34669}, 'neg': {'precision': 0.9851687787372435, 'recall': 0.9807966059117426, 'f1-score': 0.9829778306175256, 'support': 35827}, 'accuracy': 0.9827366091693146, 'macro avg': {'precision': 0.9827072789976559, 'recall': 0.9827690087737488, 'f1-score': 0.9827331416782463, 'support': 70496}, 'weighted avg': {'precision': 0.9827477127342997, 'recall': 0.9827366091693146, 'f1-score': 0.9827371610522775, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 2\n",
      "[{'pos': {'precision': 0.9800739056281979, 'recall': 0.9944909143351601, 'f1-score': 0.9872297780959198, 'support': 34670}, 'neg': {'precision': 0.9945918396239771, 'recall': 0.9804337510815865, 'f1-score': 0.9874620488024288, 'support': 35827}, 'accuracy': 0.9873469793040839, 'macro avg': {'precision': 0.9873328726260875, 'recall': 0.9874623327083734, 'f1-score': 0.9873459134491743, 'support': 70497}, 'weighted avg': {'precision': 0.9874520071256628, 'recall': 0.9873469793040839, 'f1-score': 0.9873478194679228, 'support': 70497}}, {'pos': {'precision': 0.9813291589583036, 'recall': 0.9945195996423317, 'f1-score': 0.9878803506962353, 'support': 34669}, 'neg': {'precision': 0.9946268487882131, 'recall': 0.9816897870321266, 'f1-score': 0.9881159746024611, 'support': 35827}, 'accuracy': 0.9879993191103041, 'macro avg': {'precision': 0.9879780038732584, 'recall': 0.9881046933372292, 'f1-score': 0.9879981626493481, 'support': 70496}, 'weighted avg': {'precision': 0.988087220884316, 'recall': 0.9879993191103041, 'f1-score': 0.9880000978831446, 'support': 70496}}, {'pos': {'precision': 0.9781474973074089, 'recall': 0.9954426144394127, 'f1-score': 0.9867192749210161, 'support': 34669}, 'neg': {'precision': 0.9955131481797013, 'recall': 0.9784799173807464, 'f1-score': 0.9869230444391267, 'support': 35827}, 'accuracy': 0.9868219473445302, 'macro avg': {'precision': 0.9868303227435551, 'recall': 0.9869612659100795, 'f1-score': 0.9868211596800713, 'support': 70496}, 'weighted avg': {'precision': 0.9869729508622435, 'recall': 0.9868219473445302, 'f1-score': 0.9868228332863891, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 1\n",
      "[{'pos': {'precision': 0.9813750287422396, 'recall': 0.9848283818863571, 'f1-score': 0.9830986726555528, 'support': 34670}, 'neg': {'precision': 0.9852681697241282, 'recall': 0.9819130823122226, 'f1-score': 0.983587764916401, 'support': 35827}, 'accuracy': 0.9833468090840745, 'macro avg': {'precision': 0.9833215992331839, 'recall': 0.9833707320992899, 'f1-score': 0.983343218785977, 'support': 70497}, 'weighted avg': {'precision': 0.983353546437434, 'recall': 0.9833468090840745, 'f1-score': 0.9833472322882948, 'support': 70497}}, {'pos': {'precision': 0.9847967102976949, 'recall': 0.9809051313853875, 'f1-score': 0.9828470686839785, 'support': 34669}, 'neg': {'precision': 0.981592703814926, 'recall': 0.9853462472436989, 'f1-score': 0.9834658940535721, 'support': 35827}, 'accuracy': 0.9831621652292328, 'macro avg': {'precision': 0.9831947070563105, 'recall': 0.9831256893145432, 'f1-score': 0.9831564813687753, 'support': 70496}, 'weighted avg': {'precision': 0.9831683918078776, 'recall': 0.9831621652292328, 'f1-score': 0.9831615639250764, 'support': 70496}}, {'pos': {'precision': 0.9801550832854681, 'recall': 0.9844241252992587, 'f1-score': 0.9822849659658363, 'support': 34669}, 'neg': {'precision': 0.9848637739656912, 'recall': 0.9807128701817065, 'f1-score': 0.982783939135421, 'support': 35827}, 'accuracy': 0.9825380163413527, 'macro avg': {'precision': 0.9825094286255797, 'recall': 0.9825684977404826, 'f1-score': 0.9825344525506285, 'support': 70496}, 'weighted avg': {'precision': 0.9825481021943474, 'recall': 0.9825380163413527, 'f1-score': 0.9825385507330106, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 2\n",
      "[{'pos': {'precision': 0.9796173281099189, 'recall': 0.9953273723680416, 'f1-score': 0.9874098660867575, 'support': 34670}, 'neg': {'precision': 0.9954069915794845, 'recall': 0.9799592486113825, 'f1-score': 0.9876227179386199, 'support': 35827}, 'accuracy': 0.987517199313446, 'macro avg': {'precision': 0.9875121598447016, 'recall': 0.987643310489712, 'f1-score': 0.9875162920126888, 'support': 70497}, 'weighted avg': {'precision': 0.9876417301855267, 'recall': 0.987517199313446, 'f1-score': 0.9875180386798703, 'support': 70497}}, {'pos': {'precision': 0.9806545082665757, 'recall': 0.9957310565635006, 'f1-score': 0.9881352778692162, 'support': 34669}, 'neg': {'precision': 0.9958066526888423, 'recall': 0.9809919892818265, 'f1-score': 0.988343808439139, 'support': 35827}, 'accuracy': 0.9882404675442579, 'macro avg': {'precision': 0.988230580477709, 'recall': 0.9883615229226635, 'f1-score': 0.9882395431541776, 'support': 70496}, 'weighted avg': {'precision': 0.9883550285544862, 'recall': 0.9882404675442579, 'f1-score': 0.9882412558641185, 'support': 70496}}, {'pos': {'precision': 0.9775086994653012, 'recall': 0.9966252271481727, 'f1-score': 0.9869744058500914, 'support': 34669}, 'neg': {'precision': 0.9966713135508833, 'recall': 0.9778100315404583, 'f1-score': 0.9871505861136158, 'support': 35827}, 'accuracy': 0.9870630957784838, 'macro avg': {'precision': 0.9870900065080923, 'recall': 0.9872176293443156, 'f1-score': 0.9870624959818537, 'support': 70496}, 'weighted avg': {'precision': 0.9872473935024686, 'recall': 0.9870630957784838, 'f1-score': 0.9870639429912242, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 1\n",
      "[{'pos': {'precision': 0.9801756443630746, 'recall': 0.9882895875396597, 'f1-score': 0.9842158932597986, 'support': 34670}, 'neg': {'precision': 0.9885762521102982, 'recall': 0.9806570463616825, 'f1-score': 0.9846007258256617, 'support': 35827}, 'accuracy': 0.9844106841425876, 'macro avg': {'precision': 0.9843759482366864, 'recall': 0.9844733169506711, 'f1-score': 0.9844083095427302, 'support': 70497}, 'weighted avg': {'precision': 0.9844448838166654, 'recall': 0.9844106841425876, 'f1-score': 0.9844114674875981, 'support': 70497}}, {'pos': {'precision': 0.9820481202145049, 'recall': 0.9877700539386772, 'f1-score': 0.9849007765314927, 'support': 34669}, 'neg': {'precision': 0.9880982456140351, 'recall': 0.9825271443324867, 'f1-score': 0.9853048200190337, 'support': 35827}, 'accuracy': 0.9851055379028597, 'macro avg': {'precision': 0.98507318291427, 'recall': 0.985148599135582, 'f1-score': 0.9851027982752631, 'support': 70496}, 'weighted avg': {'precision': 0.9851228739975418, 'recall': 0.9851055379028597, 'f1-score': 0.985106116778147, 'support': 70496}}, {'pos': {'precision': 0.9792101575681318, 'recall': 0.9876835213014509, 'f1-score': 0.9834285878399726, 'support': 34669}, 'neg': {'precision': 0.9879809722183128, 'recall': 0.9797080414212744, 'f1-score': 0.9838271155085909, 'support': 35827}, 'accuracy': 0.983630276895143, 'macro avg': {'precision': 0.9835955648932223, 'recall': 0.9836957813613627, 'f1-score': 0.9836278516742818, 'support': 70496}, 'weighted avg': {'precision': 0.9836676016283908, 'recall': 0.983630276895143, 'f1-score': 0.9836311248744651, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 2\n",
      "[{'pos': {'precision': 0.9792358097183218, 'recall': 0.995702336313816, 'f1-score': 0.9874004261830871, 'support': 34670}, 'neg': {'precision': 0.995772330041993, 'recall': 0.9795684818712145, 'f1-score': 0.9876039453504243, 'support': 35827}, 'accuracy': 0.9875030143126657, 'macro avg': {'precision': 0.9875040698801574, 'recall': 0.9876354090925152, 'f1-score': 0.9875021857667556, 'support': 70497}, 'weighted avg': {'precision': 0.9876397689454687, 'recall': 0.9875030143126657, 'f1-score': 0.9875038558497137, 'support': 70497}}, {'pos': {'precision': 0.9807703232403567, 'recall': 0.9959618102627708, 'f1-score': 0.9883076923076923, 'support': 34669}, 'neg': {'precision': 0.9960328705015585, 'recall': 0.9811036369218745, 'f1-score': 0.9885118888592038, 'support': 35827}, 'accuracy': 0.9884106899682251, 'macro avg': {'precision': 0.9884015968709576, 'recall': 0.9885327235923227, 'f1-score': 0.9884097905834481, 'support': 70496}, 'weighted avg': {'precision': 0.9885269517118598, 'recall': 0.9884106899682251, 'f1-score': 0.9884114676970903, 'support': 70496}}, {'pos': {'precision': 0.9779709488348387, 'recall': 0.9962502523868586, 'f1-score': 0.9870259766238962, 'support': 34669}, 'neg': {'precision': 0.9963046135478553, 'recall': 0.9782845340106624, 'f1-score': 0.9872123482522603, 'support': 35827}, 'accuracy': 0.987119836586473, 'macro avg': {'precision': 0.987137781191347, 'recall': 0.9872673931987606, 'f1-score': 0.9871191624380783, 'support': 70496}, 'weighted avg': {'precision': 0.9872883598322463, 'recall': 0.987119836586473, 'f1-score': 0.987120693151492, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pos': {'precision': 0.9810576618591128, 'recall': 0.9829535621574849, 'f1-score': 0.9820046969325861, 'support': 34670}, 'neg': {'precision': 0.9834731543624161, 'recall': 0.9816339632121026, 'f1-score': 0.9825526981155797, 'support': 35827}, 'accuracy': 0.9822829340255613, 'macro avg': {'precision': 0.9822654081107645, 'recall': 0.9822937626847937, 'f1-score': 0.9822786975240829, 'support': 70497}, 'weighted avg': {'precision': 0.9822852296976854, 'recall': 0.9822829340255613, 'f1-score': 0.982283194434368, 'support': 70497}}, {'pos': {'precision': 0.9840434757472394, 'recall': 0.9819146788196949, 'f1-score': 0.9829779247217129, 'support': 34669}, 'neg': {'precision': 0.9825357918778899, 'recall': 0.9845926256733748, 'f1-score': 0.9835631334606645, 'support': 35827}, 'accuracy': 0.9832756468452111, 'macro avg': {'precision': 0.9832896338125646, 'recall': 0.9832536522465348, 'f1-score': 0.9832705290911887, 'support': 70496}, 'weighted avg': {'precision': 0.9832772508552287, 'recall': 0.9832756468452111, 'f1-score': 0.9832753355463044, 'support': 70496}}, {'pos': {'precision': 0.9798580582133725, 'recall': 0.9836453315642216, 'f1-score': 0.9817480423767849, 'support': 34669}, 'neg': {'precision': 0.9841145322612277, 'recall': 0.9804337510815865, 'f1-score': 0.9822706935123041, 'support': 35827}, 'accuracy': 0.9820131638674535, 'macro avg': {'precision': 0.9819862952373001, 'recall': 0.982039541322904, 'f1-score': 0.9820093679445445, 'support': 70496}, 'weighted avg': {'precision': 0.9820212546459717, 'recall': 0.9820131638674535, 'f1-score': 0.9820136605995528, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 2\n",
      "[{'pos': {'precision': 0.9797233976088376, 'recall': 0.9950677819440439, 'f1-score': 0.9873359758453415, 'support': 34670}, 'neg': {'precision': 0.9951536107017345, 'recall': 0.9800708962514305, 'f1-score': 0.9875546680541688, 'support': 35827}, 'accuracy': 0.9874462743095451, 'macro avg': {'precision': 0.987438504155286, 'recall': 0.9875693390977371, 'f1-score': 0.9874453219497552, 'support': 70497}, 'weighted avg': {'precision': 0.9875651248380702, 'recall': 0.9874462743095451, 'f1-score': 0.9874471165430402, 'support': 70497}}, {'pos': {'precision': 0.9815463477146519, 'recall': 0.9941734690934264, 'f1-score': 0.9878195574916887, 'support': 34669}, 'neg': {'precision': 0.9942907210084508, 'recall': 0.9819130823122226, 'f1-score': 0.9880631389731491, 'support': 35827}, 'accuracy': 0.987942578302315, 'macro avg': {'precision': 0.9879185343615513, 'recall': 0.9880432757028246, 'f1-score': 0.9879413482324189, 'support': 70496}, 'weighted avg': {'precision': 0.9880232068555524, 'recall': 0.987942578302315, 'f1-score': 0.9879433488236264, 'support': 70496}}, {'pos': {'precision': 0.978145019558932, 'recall': 0.9953272375897776, 'f1-score': 0.9866613292921783, 'support': 34669}, 'neg': {'precision': 0.9954000795047987, 'recall': 0.9784799173807464, 'f1-score': 0.9868674783587867, 'support': 35827}, 'accuracy': 0.9867652065365411, 'macro avg': {'precision': 0.9867725495318653, 'recall': 0.9869035774852619, 'f1-score': 0.9867644038254826, 'support': 70496}, 'weighted avg': {'precision': 0.9869142693416227, 'recall': 0.9867652065365411, 'f1-score': 0.9867660969755842, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 1\n",
      "[{'pos': {'precision': 0.9827077670464404, 'recall': 0.980213441015287, 'f1-score': 0.9814590192341016, 'support': 34670}, 'neg': {'precision': 0.9808993456772936, 'recall': 0.9833086778128227, 'f1-score': 0.982102534080455, 'support': 35827}, 'accuracy': 0.9817864589982552, 'macro avg': {'precision': 0.981803556361867, 'recall': 0.9817610594140549, 'f1-score': 0.9817807766572784, 'support': 70497}, 'weighted avg': {'precision': 0.9817887164146061, 'recall': 0.9817864589982552, 'f1-score': 0.9817860573548771, 'support': 70497}}, {'pos': {'precision': 0.9825616529020748, 'recall': 0.9848856326977992, 'f1-score': 0.9837222702391242, 'support': 34669}, 'neg': {'precision': 0.985340607077913, 'recall': 0.9830853825327267, 'f1-score': 0.9842117029005757, 'support': 35827}, 'accuracy': 0.9839707217430776, 'macro avg': {'precision': 0.9839511299899939, 'recall': 0.9839855076152629, 'f1-score': 0.9839669865698499, 'support': 70496}, 'weighted avg': {'precision': 0.9839739541852361, 'recall': 0.9839707217430776, 'f1-score': 0.9839710063938254, 'support': 70496}}, {'pos': {'precision': 0.9790199782471807, 'recall': 0.986616285442326, 'f1-score': 0.982803453675636, 'support': 34669}, 'neg': {'precision': 0.9869508971258226, 'recall': 0.9795405699612024, 'f1-score': 0.9832317713805421, 'support': 35827}, 'accuracy': 0.9830203132092601, 'macro avg': {'precision': 0.9829854376865017, 'recall': 0.9830784277017642, 'f1-score': 0.9830176125280891, 'support': 70496}, 'weighted avg': {'precision': 0.9830505761628795, 'recall': 0.9830203132092601, 'f1-score': 0.9830211304007503, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 2\n",
      "[{'pos': {'precision': 0.9809274388681716, 'recall': 0.9939140467262764, 'f1-score': 0.9873780426653678, 'support': 34670}, 'neg': {'precision': 0.9940341551685139, 'recall': 0.9812990202919586, 'f1-score': 0.9876255355010887, 'support': 35827}, 'accuracy': 0.9875030143126657, 'macro avg': {'precision': 0.9874807970183428, 'recall': 0.9876065335091175, 'f1-score': 0.9875017890832283, 'support': 70497}, 'weighted avg': {'precision': 0.9875883510331199, 'recall': 0.9875030143126657, 'f1-score': 0.9875038200151185, 'support': 70497}}, {'pos': {'precision': 0.9816628701594533, 'recall': 0.9944330670051055, 'f1-score': 0.9880067059278682, 'support': 34669}, 'neg': {'precision': 0.9945443238353686, 'recall': 0.9820247299522706, 'f1-score': 0.9882448773225847, 'support': 35827}, 'accuracy': 0.9881269859282796, 'macro avg': {'precision': 0.988103596997411, 'recall': 0.988228898478688, 'f1-score': 0.9881257916252264, 'support': 70496}, 'weighted avg': {'precision': 0.9882093953643872, 'recall': 0.9881269859282796, 'f1-score': 0.9881277477821367, 'support': 70496}}, {'pos': {'precision': 0.9787179705456712, 'recall': 0.9948657301912371, 'f1-score': 0.9867257903018166, 'support': 34669}, 'neg': {'precision': 0.9949510707701036, 'recall': 0.9790660674909984, 'f1-score': 0.9869446554683324, 'support': 35827}, 'accuracy': 0.9868361325465275, 'macro avg': {'precision': 0.9868345206578875, 'recall': 0.9869658988411179, 'f1-score': 0.9868352228850745, 'support': 70496}, 'weighted avg': {'precision': 0.9869678468754026, 'recall': 0.9868361325465275, 'f1-score': 0.9868370204754544, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 1\n",
      "[{'pos': {'precision': 0.9801335894275148, 'recall': 0.9861551773867897, 'f1-score': 0.9831351631130217, 'support': 34670}, 'neg': {'precision': 0.9865221542090189, 'recall': 0.9806570463616825, 'f1-score': 0.9835808569308939, 'support': 35827}, 'accuracy': 0.9833609940848547, 'macro avg': {'precision': 0.9833278718182669, 'recall': 0.9834061118742361, 'f1-score': 0.9833580100219579, 'support': 70497}, 'weighted avg': {'precision': 0.9833802965274901, 'recall': 0.9833609940848547, 'f1-score': 0.9833616673956567, 'support': 70497}}, {'pos': {'precision': 0.9821551724137931, 'recall': 0.9858663359196977, 'f1-score': 0.9840072550346198, 'support': 34669}, 'neg': {'precision': 0.9862729717615419, 'recall': 0.9826667038825467, 'f1-score': 0.9844665352404123, 'support': 35827}, 'accuracy': 0.9842402405810259, 'macro avg': {'precision': 0.9842140720876675, 'recall': 0.9842665199011222, 'f1-score': 0.984236895137516, 'support': 70496}, 'weighted avg': {'precision': 0.9842478925288606, 'recall': 0.9842402405810259, 'f1-score': 0.9842406673123791, 'support': 70496}}, {'pos': {'precision': 0.978482025490084, 'recall': 0.9876546770890421, 'f1-score': 0.983046954624406, 'support': 34669}, 'neg': {'precision': 0.9879443411638781, 'recall': 0.9789823317609624, 'f1-score': 0.983442919429685, 'support': 35827}, 'accuracy': 0.9832472764412166, 'macro avg': {'precision': 0.983213183326981, 'recall': 0.9833185044250022, 'f1-score': 0.9832449370270455, 'support': 70496}, 'weighted avg': {'precision': 0.9832908995204549, 'recall': 0.9832472764412166, 'f1-score': 0.983248189177838, 'support': 70496}}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 2\n",
      "[{'pos': {'precision': 0.979264176098488, 'recall': 0.9957311796942602, 'f1-score': 0.9874290290748394, 'support': 34670}, 'neg': {'precision': 0.9958007036658723, 'recall': 0.9795963937812264, 'f1-score': 0.9876320862236355, 'support': 35827}, 'accuracy': 0.9875313843142262, 'macro avg': {'precision': 0.9875324398821801, 'recall': 0.9876637867377434, 'f1-score': 0.9875305576492375, 'support': 70497}, 'weighted avg': {'precision': 0.9876681390069335, 'recall': 0.9875313843142262, 'f1-score': 0.9875322239408609, 'support': 70497}}, {'pos': {'precision': 0.9810650214653285, 'recall': 0.9953272375897776, 'f1-score': 0.9881446693966381, 'support': 34669}, 'neg': {'precision': 0.9954137530787306, 'recall': 0.9814106679320066, 'f1-score': 0.988362614195362, 'support': 35827}, 'accuracy': 0.9882546527462551, 'macro avg': {'precision': 0.9882393872720295, 'recall': 0.9883689527608921, 'f1-score': 0.9882536417960001, 'support': 70496}, 'weighted avg': {'precision': 0.9883572367330508, 'recall': 0.9882546527462551, 'f1-score': 0.9882554318271856, 'support': 70496}}, {'pos': {'precision': 0.9777192684445954, 'recall': 0.9961348755372235, 'f1-score': 0.9868411652926805, 'support': 34669}, 'neg': {'precision': 0.9961903678853699, 'recall': 0.9780333268205543, 'f1-score': 0.9870283517133561, 'support': 35827}, 'accuracy': 0.9869354289605083, 'macro avg': {'precision': 0.9869548181649827, 'recall': 0.9870841011788889, 'f1-score': 0.9869347585030184, 'support': 70496}, 'weighted avg': {'precision': 0.98710652558918, 'recall': 0.9869354289605083, 'f1-score': 0.9869362959085105, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 1\n",
      "[{'pos': {'precision': 0.9814425871047558, 'recall': 0.983905393712143, 'f1-score': 0.9826724473187665, 'support': 34670}, 'neg': {'precision': 0.9843872411863458, 'recall': 0.9819968180422586, 'f1-score': 0.9831905766624282, 'support': 35827}, 'accuracy': 0.9829354440614494, 'macro avg': {'precision': 0.9829149141455509, 'recall': 0.9829511058772008, 'f1-score': 0.9829315119905973, 'support': 70497}, 'weighted avg': {'precision': 0.9829390780445281, 'recall': 0.9829354440614494, 'f1-score': 0.9829357637718832, 'support': 70497}}, {'pos': {'precision': 0.9838639840660451, 'recall': 0.9831261357408636, 'f1-score': 0.9834949215143121, 'support': 34669}, 'neg': {'precision': 0.983683373776253, 'recall': 0.9843972423032908, 'f1-score': 0.9840401785714287, 'support': 35827}, 'accuracy': 0.9837721289151158, 'macro avg': {'precision': 0.9837736789211491, 'recall': 0.9837616890220773, 'f1-score': 0.9837675500428704, 'support': 70496}, 'weighted avg': {'precision': 0.9837721955269453, 'recall': 0.9837721289151158, 'f1-score': 0.9837720283655562, 'support': 70496}}, {'pos': {'precision': 0.9794520547945206, 'recall': 0.9858086474948802, 'f1-score': 0.9826200710147637, 'support': 34669}, 'neg': {'precision': 0.9861805516544014, 'recall': 0.9799871605213945, 'f1-score': 0.9830741015553907, 'support': 35827}, 'accuracy': 0.9828500907852927, 'macro avg': {'precision': 0.982816303224461, 'recall': 0.9828979040081374, 'f1-score': 0.9828470862850771, 'support': 70496}, 'weighted avg': {'precision': 0.9828715659298892, 'recall': 0.9828500907852927, 'f1-score': 0.9828508153432226, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 2\n",
      "[{'pos': {'precision': 0.979206263652095, 'recall': 0.9956158061724835, 'f1-score': 0.9873428583687305, 'support': 34670}, 'neg': {'precision': 0.9956874538954775, 'recall': 0.9795405699612024, 'f1-score': 0.9875480140137605, 'support': 35827}, 'accuracy': 0.9874462743095451, 'macro avg': {'precision': 0.9874468587737862, 'recall': 0.9875781880668429, 'f1-score': 0.9874454361912455, 'support': 70497}, 'weighted avg': {'precision': 0.9875821037991886, 'recall': 0.9874462743095451, 'f1-score': 0.9874471197031771, 'support': 70497}}, {'pos': {'precision': 0.9815283904938096, 'recall': 0.9947215091291932, 'f1-score': 0.9880809122686378, 'support': 34669}, 'neg': {'precision': 0.9948248069907525, 'recall': 0.9818851704022106, 'f1-score': 0.9883126369612856, 'support': 35827}, 'accuracy': 0.988197911938266, 'macro avg': {'precision': 0.988176598742281, 'recall': 0.988303339765702, 'f1-score': 0.9881967746149617, 'support': 70496}, 'weighted avg': {'precision': 0.9882858052951596, 'recall': 0.988197911938266, 'f1-score': 0.9881986778236124, 'support': 70496}}, {'pos': {'precision': 0.9778797405613617, 'recall': 0.9958752776255444, 'f1-score': 0.9867954727335086, 'support': 34669}, 'neg': {'precision': 0.9959362300718975, 'recall': 0.9782007982806263, 'f1-score': 0.9869888475836431, 'support': 35827}, 'accuracy': 0.9868928733545166, 'macro avg': {'precision': 0.9869079853166296, 'recall': 0.9870380379530854, 'f1-score': 0.9868921601585758, 'support': 70496}, 'weighted avg': {'precision': 0.9870562874532983, 'recall': 0.9868928733545166, 'f1-score': 0.9868937483910745, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 1\n",
      "[{'pos': {'precision': 0.9799403943145346, 'recall': 0.9863282376694549, 'f1-score': 0.9831239398556767, 'support': 34670}, 'neg': {'precision': 0.9866857672537288, 'recall': 0.9804616629915985, 'f1-score': 0.983563868510948, 'support': 35827}, 'accuracy': 0.9833468090840745, 'macro avg': {'precision': 0.9833130807841317, 'recall': 0.9833949503305267, 'f1-score': 0.9833439041833123, 'support': 70497}, 'weighted avg': {'precision': 0.983368433469286, 'recall': 0.9833468090840745, 'f1-score': 0.9833475142479544, 'support': 70497}}, {'pos': {'precision': 0.9837630501240122, 'recall': 0.9839049294759007, 'f1-score': 0.9838339846848277, 'support': 34669}, 'neg': {'precision': 0.984422980291441, 'recall': 0.9842855946632428, 'f1-score': 0.9843542826836383, 'support': 35827}, 'accuracy': 0.9840983885610531, 'macro avg': {'precision': 0.9840930152077266, 'recall': 0.9840952620695718, 'f1-score': 0.984094133684233, 'support': 70496}, 'weighted avg': {'precision': 0.9840984353672668, 'recall': 0.9840983885610531, 'f1-score': 0.9840984070123837, 'support': 70496}}, {'pos': {'precision': 0.981580545354654, 'recall': 0.9791456344284519, 'f1-score': 0.9803615780049674, 'support': 34669}, 'neg': {'precision': 0.9798680143680562, 'recall': 0.9822201133223546, 'f1-score': 0.981042654028436, 'support': 35827}, 'accuracy': 0.980708125283704, 'macro avg': {'precision': 0.9807242798613551, 'recall': 0.9806828738754032, 'f1-score': 0.9807021160167018, 'support': 70496}, 'weighted avg': {'precision': 0.9807102144471298, 'recall': 0.980708125283704, 'f1-score': 0.9807077098520623, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 5 2\n",
      "[{'pos': {'precision': 0.9796434046902505, 'recall': 0.9952408422267089, 'f1-score': 0.9873805299605105, 'support': 34670}, 'neg': {'precision': 0.9953224663359319, 'recall': 0.9799871605213945, 'f1-score': 0.9875952856459733, 'support': 35827}, 'accuracy': 0.9874888293118856, 'macro avg': {'precision': 0.9874829355130912, 'recall': 0.9876140013740518, 'f1-score': 0.9874879078032419, 'support': 70497}, 'weighted avg': {'precision': 0.9876115982528111, 'recall': 0.9874888293118856, 'f1-score': 0.9874896700933257, 'support': 70497}}, {'pos': {'precision': 0.9814081940608718, 'recall': 0.9942600017306528, 'f1-score': 0.9877922971114168, 'support': 34669}, 'neg': {'precision': 0.9943742402397309, 'recall': 0.9817735227621626, 'f1-score': 0.9880337078651686, 'support': 35827}, 'accuracy': 0.9879142078983205, 'macro avg': {'precision': 0.9878912171503014, 'recall': 0.9880167622464077, 'f1-score': 0.9879130024882927, 'support': 70496}, 'weighted avg': {'precision': 0.9879977102951258, 'recall': 0.9879142078983205, 'f1-score': 0.9879149852508101, 'support': 70496}}, {'pos': {'precision': 0.9789088225275349, 'recall': 0.9946926649167844, 'f1-score': 0.9867376282243873, 'support': 34669}, 'neg': {'precision': 0.9947828059430646, 'recall': 0.9792614508610824, 'f1-score': 0.9869611083761165, 'support': 35827}, 'accuracy': 0.9868503177485247, 'macro avg': {'precision': 0.9868458142352997, 'recall': 0.9869770578889334, 'f1-score': 0.9868493683002519, 'support': 70496}, 'weighted avg': {'precision': 0.986976190943164, 'recall': 0.9868503177485247, 'f1-score': 0.9868512037945757, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 1\n",
      "[{'pos': {'precision': 0.98273173548946, 'recall': 0.981597923276608, 'f1-score': 0.9821645021645021, 'support': 34670}, 'neg': {'precision': 0.9822120612261968, 'recall': 0.9833086778128227, 'f1-score': 0.9827600636036489, 'support': 35827}, 'accuracy': 0.9824673390357036, 'macro avg': {'precision': 0.9824718983578284, 'recall': 0.9824533005447154, 'f1-score': 0.9824622828840754, 'support': 70497}, 'weighted avg': {'precision': 0.9824676338988969, 'recall': 0.9824673390357036, 'f1-score': 0.9824671700749141, 'support': 70497}}, {'pos': {'precision': 0.9841600184992485, 'recall': 0.9820877440941476, 'f1-score': 0.983122789287519, 'support': 34669}, 'neg': {'precision': 0.9827019498607242, 'recall': 0.9847042733134228, 'f1-score': 0.9837020926568795, 'support': 35827}, 'accuracy': 0.9834174988651838, 'macro avg': {'precision': 0.9834309841799864, 'recall': 0.9833960087037852, 'f1-score': 0.9834124409721992, 'support': 70496}, 'weighted avg': {'precision': 0.9834190087240499, 'recall': 0.9834174988651838, 'f1-score': 0.9834171989251448, 'support': 70496}}, {'pos': {'precision': 0.9802315892308134, 'recall': 0.9840203063255358, 'f1-score': 0.9821222938737909, 'support': 34669}, 'neg': {'precision': 0.9844787493346034, 'recall': 0.9807966059117426, 'f1-score': 0.9826342281879195, 'support': 35827}, 'accuracy': 0.9823819791193826, 'macro avg': {'precision': 0.9823551692827084, 'recall': 0.9824084561186393, 'f1-score': 0.9823782610308551, 'support': 70496}, 'weighted avg': {'precision': 0.9823900521937969, 'recall': 0.9823819791193826, 'f1-score': 0.9823824656661234, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 1 10 2\n",
      "[{'pos': {'precision': 0.9799937480462645, 'recall': 0.9946639746178252, 'f1-score': 0.9872743669391203, 'support': 34670}, 'neg': {'precision': 0.9947603942449303, 'recall': 0.9803500153515505, 'f1-score': 0.9875026358332748, 'support': 35827}, 'accuracy': 0.9873895343064244, 'macro avg': {'precision': 0.9873770711455974, 'recall': 0.9875069949846879, 'f1-score': 0.9873885013861976, 'support': 70497}, 'weighted avg': {'precision': 0.9874982465832179, 'recall': 0.9873895343064244, 'f1-score': 0.9873903745659821, 'support': 70497}}, {'pos': {'precision': 0.981755466233359, 'recall': 0.9933658311459805, 'f1-score': 0.9875265240580375, 'support': 34669}, 'neg': {'precision': 0.9935059434734732, 'recall': 0.9821363775923186, 'f1-score': 0.9877884453427657, 'support': 35827}, 'accuracy': 0.9876588742623695, 'macro avg': {'precision': 0.9876307048534161, 'recall': 0.9877511043691496, 'f1-score': 0.9876574847004016, 'support': 70496}, 'weighted avg': {'precision': 0.9877272142485878, 'recall': 0.9876588742623695, 'f1-score': 0.9876596359206675, 'support': 70496}}, {'pos': {'precision': 0.9783046425229006, 'recall': 0.9950099512532811, 'f1-score': 0.9865865865865866, 'support': 34669}, 'neg': {'precision': 0.9950901092663544, 'recall': 0.9786473888408184, 'f1-score': 0.9868002589288227, 'support': 35827}, 'accuracy': 0.9866942805265547, 'macro avg': {'precision': 0.9866973758946276, 'recall': 0.9868286700470497, 'f1-score': 0.9866934227577047, 'support': 70496}, 'weighted avg': {'precision': 0.9868352388264883, 'recall': 0.9866942805265547, 'f1-score': 0.9866951776982142, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 1\n",
      "[{'pos': {'precision': 0.9814287767715969, 'recall': 0.9846841649841361, 'f1-score': 0.9830537758260743, 'support': 34670}, 'neg': {'precision': 0.9851310483870968, 'recall': 0.9819689061322466, 'f1-score': 0.9835474356644628, 'support': 35827}, 'accuracy': 0.9833042540817339, 'macro avg': {'precision': 0.9832799125793468, 'recall': 0.9833265355581914, 'f1-score': 0.9833006057452686, 'support': 70497}, 'weighted avg': {'precision': 0.9833102935051958, 'recall': 0.9833042540817339, 'f1-score': 0.9833046567292325, 'support': 70497}}, {'pos': {'precision': 0.9843637099338132, 'recall': 0.9823761862182353, 'f1-score': 0.9833689438124387, 'support': 34669}, 'neg': {'precision': 0.9829790790316739, 'recall': 0.9848996566835069, 'f1-score': 0.9839384306508282, 'support': 35827}, 'accuracy': 0.9836586472991375, 'macro avg': {'precision': 0.9836713944827435, 'recall': 0.983637921450871, 'f1-score': 0.9836536872316335, 'support': 70496}, 'weighted avg': {'precision': 0.9836600221879703, 'recall': 0.9836586472991375, 'f1-score': 0.9836583645591332, 'support': 70496}}, {'pos': {'precision': 0.9804293473575308, 'recall': 0.9840491505379446, 'f1-score': 0.982235913972303, 'support': 34669}, 'neg': {'precision': 0.9845093700103644, 'recall': 0.9809919892818265, 'f1-score': 0.982747532365853, 'support': 35827}, 'accuracy': 0.9824954607353609, 'macro avg': {'precision': 0.9824693586839477, 'recall': 0.9825205699098856, 'f1-score': 0.982491723169078, 'support': 70496}, 'weighted avg': {'precision': 0.9825028688563828, 'recall': 0.9824954607353609, 'f1-score': 0.9824959252096173, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 5 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'pos': {'precision': 0.979264176098488, 'recall': 0.9957311796942602, 'f1-score': 0.9874290290748394, 'support': 34670}, 'neg': {'precision': 0.9958007036658723, 'recall': 0.9795963937812264, 'f1-score': 0.9876320862236355, 'support': 35827}, 'accuracy': 0.9875313843142262, 'macro avg': {'precision': 0.9875324398821801, 'recall': 0.9876637867377434, 'f1-score': 0.9875305576492375, 'support': 70497}, 'weighted avg': {'precision': 0.9876681390069335, 'recall': 0.9875313843142262, 'f1-score': 0.9875322239408609, 'support': 70497}}, {'pos': {'precision': 0.9813945549202014, 'recall': 0.9950387954656899, 'f1-score': 0.9881695789172157, 'support': 34669}, 'neg': {'precision': 0.9951336822747207, 'recall': 0.9817456108521506, 'f1-score': 0.9883943123700332, 'support': 35827}, 'accuracy': 0.9882830231502496, 'macro avg': {'precision': 0.988264118597461, 'recall': 0.9883922031589203, 'f1-score': 0.9882819456436245, 'support': 70496}, 'weighted avg': {'precision': 0.9883769612373028, 'recall': 0.9882830231502496, 'f1-score': 0.9882837914316007, 'support': 70496}}, {'pos': {'precision': 0.9780465695994561, 'recall': 0.9959041218379532, 'f1-score': 0.9868945706078232, 'support': 34669}, 'neg': {'precision': 0.9959652213445473, 'recall': 0.9783682697406983, 'f1-score': 0.9870883259880879, 'support': 35827}, 'accuracy': 0.9869921697684975, 'macro avg': {'precision': 0.9870058954720018, 'recall': 0.9871361957893258, 'f1-score': 0.9869914482979556, 'support': 70496}, 'weighted avg': {'precision': 0.9871530655151306, 'recall': 0.9869921697684975, 'f1-score': 0.9869930396558366, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 1\n",
      "[{'pos': {'precision': 0.9813438190637467, 'recall': 0.9861840207672339, 'f1-score': 0.9837579663650357, 'support': 34670}, 'neg': {'precision': 0.986566075835764, 'recall': 0.9818572584921986, 'f1-score': 0.9842060350013289, 'support': 35827}, 'accuracy': 0.9839851341191824, 'macro avg': {'precision': 0.9839549474497553, 'recall': 0.9840206396297162, 'f1-score': 0.9839820006831823, 'support': 70497}, 'weighted avg': {'precision': 0.9839978014086841, 'recall': 0.9839851341191824, 'f1-score': 0.9839856775446955, 'support': 70497}}, {'pos': {'precision': 0.9842810910772076, 'recall': 0.982549251492688, 'f1-score': 0.983414408822553, 'support': 34669}, 'neg': {'precision': 0.9831419973250112, 'recall': 0.9848159209534708, 'f1-score': 0.9839782472286134, 'support': 35827}, 'accuracy': 0.9837012029051294, 'macro avg': {'precision': 0.9837115442011094, 'recall': 0.9836825862230794, 'f1-score': 0.9836963280255833, 'support': 70496}, 'weighted avg': {'precision': 0.9837021885599025, 'recall': 0.9837012029051294, 'f1-score': 0.9837009589611982, 'support': 70496}}, {'pos': {'precision': 0.9789404503371814, 'recall': 0.9881738729124001, 'f1-score': 0.9835354912796956, 'support': 34669}, 'neg': {'precision': 0.9884507042253521, 'recall': 0.9794289223211544, 'f1-score': 0.9839191330071361, 'support': 35827}, 'accuracy': 0.9837295733091239, 'macro avg': {'precision': 0.9836955772812668, 'recall': 0.9838013976167772, 'f1-score': 0.9837273121434158, 'support': 70496}, 'weighted avg': {'precision': 0.9837736872024146, 'recall': 0.9837295733091239, 'f1-score': 0.9837304630819116, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "30 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "30 0.1 10 2\n",
      "[{'pos': {'precision': 0.9793475177304964, 'recall': 0.9957311796942602, 'f1-score': 0.9874713958810069, 'support': 34670}, 'neg': {'precision': 0.9958010610832128, 'recall': 0.9796801295112625, 'f1-score': 0.9876748177955371, 'support': 35827}, 'accuracy': 0.9875739393165667, 'macro avg': {'precision': 0.9875742894068547, 'recall': 0.9877056546027614, 'f1-score': 0.987573106838272, 'support': 70497}, 'weighted avg': {'precision': 0.9877093075612378, 'recall': 0.9875739393165667, 'f1-score': 0.9875747761231715, 'support': 70497}}, {'pos': {'precision': 0.9809009521102743, 'recall': 0.9955003028642303, 'f1-score': 0.9881467059867723, 'support': 34669}, 'neg': {'precision': 0.9955821132225086, 'recall': 0.9812431964719346, 'f1-score': 0.9883606511287919, 'support': 35827}, 'accuracy': 0.9882546527462551, 'macro avg': {'precision': 0.9882415326663914, 'recall': 0.9883717496680824, 'f1-score': 0.9882536785577821, 'support': 70496}, 'weighted avg': {'precision': 0.9883621124479958, 'recall': 0.9882546527462551, 'f1-score': 0.9882554357388595, 'support': 70496}}, {'pos': {'precision': 0.977938885899578, 'recall': 0.9960483428999971, 'f1-score': 0.9869105458702487, 'support': 34669}, 'neg': {'precision': 0.996106295296291, 'recall': 0.9782566221006503, 'f1-score': 0.9871007717005578, 'support': 35827}, 'accuracy': 0.9870063549704948, 'macro avg': {'precision': 0.9870225905979345, 'recall': 0.9871524825003237, 'f1-score': 0.9870056587854033, 'support': 70496}, 'weighted avg': {'precision': 0.9871718037453568, 'recall': 0.9870063549704948, 'f1-score': 0.9870072211542718, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 1\n",
      "[{'pos': {'precision': 0.9802125215393452, 'recall': 0.9844534179405826, 'f1-score': 0.9823283925744711, 'support': 34670}, 'neg': {'precision': 0.9848922274854949, 'recall': 0.9807686940017305, 'f1-score': 0.9828261356008056, 'support': 35827}, 'accuracy': 0.982580819041945, 'macro avg': {'precision': 0.9825523745124201, 'recall': 0.9826110559711565, 'f1-score': 0.9825772640876383, 'support': 70497}, 'weighted avg': {'precision': 0.9825907762868195, 'recall': 0.982580819041945, 'f1-score': 0.9825813485783363, 'support': 70497}}, {'pos': {'precision': 0.9825420603825766, 'recall': 0.9837607084138568, 'f1-score': 0.9831510067597757, 'support': 34669}, 'neg': {'precision': 0.9842667113793875, 'recall': 0.9830853825327267, 'f1-score': 0.9836756922819121, 'support': 35827}, 'accuracy': 0.9834174988651838, 'macro avg': {'precision': 0.983404385880982, 'recall': 0.9834230454732917, 'f1-score': 0.9834133495208439, 'support': 70496}, 'weighted avg': {'precision': 0.9834185508396627, 'recall': 0.9834174988651838, 'f1-score': 0.9834176588847414, 'support': 70496}}, {'pos': {'precision': 0.978195016003658, 'recall': 0.9873085465401367, 'f1-score': 0.9827306527325189, 'support': 34669}, 'neg': {'precision': 0.9876070301937809, 'recall': 0.9787032126608424, 'f1-score': 0.9831349623585818, 'support': 35827}, 'accuracy': 0.9829352019972765, 'macro avg': {'precision': 0.9829010230987194, 'recall': 0.9830058796004895, 'f1-score': 0.9829328075455503, 'support': 70496}, 'weighted avg': {'precision': 0.98297832615444, 'recall': 0.9829352019972765, 'f1-score': 0.9829361282342916, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 5 2\n",
      "[{'pos': {'precision': 0.9797477702664319, 'recall': 0.9948947216613787, 'f1-score': 0.9872631518690251, 'support': 34670}, 'neg': {'precision': 0.994984556969199, 'recall': 0.9800988081614425, 'f1-score': 0.987485587333727, 'support': 35827}, 'accuracy': 0.9873753493056442, 'macro avg': {'precision': 0.9873661636178155, 'recall': 0.9874967649114106, 'f1-score': 0.9873743696013761, 'support': 70497}, 'weighted avg': {'precision': 0.9874911970392029, 'recall': 0.9873753493056442, 'f1-score': 0.9873761949119046, 'support': 70497}}, {'pos': {'precision': 0.9817410129322622, 'recall': 0.9941157806686088, 'f1-score': 0.9878896452884272, 'support': 34669}, 'neg': {'precision': 0.9942356597909013, 'recall': 0.9821084656823066, 'f1-score': 0.9881348554418187, 'support': 35827}, 'accuracy': 0.9880135043123014, 'macro avg': {'precision': 0.9879883363615818, 'recall': 0.9881121231754577, 'f1-score': 0.988012250365123, 'support': 70496}, 'weighted avg': {'precision': 0.9880909577944453, 'recall': 0.9880135043123014, 'f1-score': 0.9880142643329908, 'support': 70496}}, {'pos': {'precision': 0.9786117493546649, 'recall': 0.9950964838905074, 'f1-score': 0.9867852750207374, 'support': 34669}, 'neg': {'precision': 0.9951763470760151, 'recall': 0.9789544198509504, 'f1-score': 0.9869987336428873, 'support': 35827}, 'accuracy': 0.9868928733545166, 'macro avg': {'precision': 0.98689404821534, 'recall': 0.9870254518707289, 'f1-score': 0.9868920043318123, 'support': 70496}, 'weighted avg': {'precision': 0.9870300970986903, 'recall': 0.9868928733545166, 'f1-score': 0.9868937575169894, 'support': 70496}}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 1\n",
      "[{'pos': {'precision': 0.9813546642113138, 'recall': 0.983732333429478, 'f1-score': 0.9825420603825767, 'support': 34670}, 'neg': {'precision': 0.9842206865679993, 'recall': 0.9819130823122226, 'f1-score': 0.9830655302501049, 'support': 35827}, 'accuracy': 0.9828077790544278, 'macro avg': {'precision': 0.9827876753896565, 'recall': 0.9828227078708502, 'f1-score': 0.9828037953163409, 'support': 70497}, 'weighted avg': {'precision': 0.9828111940348946, 'recall': 0.9828077790544278, 'f1-score': 0.982808090922088, 'support': 70497}}, {'pos': {'precision': 0.9828921978053627, 'recall': 0.9843664368744411, 'f1-score': 0.9836287649517221, 'support': 34669}, 'neg': {'precision': 0.9848497554157931, 'recall': 0.9834203254528707, 'f1-score': 0.9841345213820843, 'support': 35827}, 'accuracy': 0.9838856105310939, 'macro avg': {'precision': 0.983870976610578, 'recall': 0.9838933811636559, 'f1-score': 0.9838816431669033, 'support': 70496}, 'weighted avg': {'precision': 0.9838870544853003, 'recall': 0.9838856105310939, 'f1-score': 0.9838857970617791, 'support': 70496}}, {'pos': {'precision': 0.982067724806314, 'recall': 0.9762323689751652, 'f1-score': 0.9791413527744026, 'support': 34669}, 'neg': {'precision': 0.977132073377182, 'recall': 0.9827504396125827, 'f1-score': 0.979933203451155, 'support': 35827}, 'accuracy': 0.9795449387199274, 'macro avg': {'precision': 0.979599899091748, 'recall': 0.9794914042938739, 'f1-score': 0.9795372781127788, 'support': 70496}, 'weighted avg': {'precision': 0.9795593614417044, 'recall': 0.9795449387199274, 'f1-score': 0.9795437817660619, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 1 10 2\n",
      "[{'pos': {'precision': 0.9805852880892735, 'recall': 0.9935390827805018, 'f1-score': 0.9870196853778045, 'support': 34670}, 'neg': {'precision': 0.9936667703356046, 'recall': 0.9809640773718146, 'f1-score': 0.9872745659868531, 'support': 35827}, 'accuracy': 0.9871483892931614, 'macro avg': {'precision': 0.9871260292124391, 'recall': 0.9872515800761582, 'f1-score': 0.9871471256823288, 'support': 70497}, 'weighted avg': {'precision': 0.9872333761559899, 'recall': 0.9871483892931614, 'f1-score': 0.9871492172384565, 'support': 70497}}, {'pos': {'precision': 0.9817404928072924, 'recall': 0.9940869364562, 'f1-score': 0.9878751397368647, 'support': 34669}, 'neg': {'precision': 0.9942075668955385, 'recall': 0.9821084656823066, 'f1-score': 0.988120980650959, 'support': 35827}, 'accuracy': 0.9879993191103041, 'macro avg': {'precision': 0.9879740298514155, 'recall': 0.9880977010692533, 'f1-score': 0.9879980601939118, 'support': 70496}, 'weighted avg': {'precision': 0.9880764248227201, 'recall': 0.9879993191103041, 'f1-score': 0.9880000793423638, 'support': 70496}}, {'pos': {'precision': 0.9784415510736675, 'recall': 0.9949234186160547, 'f1-score': 0.9866136552158119, 'support': 34669}, 'neg': {'precision': 0.9950061005022274, 'recall': 0.9787869483908784, 'f1-score': 0.9868298860278599, 'support': 35827}, 'accuracy': 0.9867226509305492, 'macro avg': {'precision': 0.9867238257879474, 'recall': 0.9868551835034666, 'f1-score': 0.9867217706218359, 'support': 70496}, 'weighted avg': {'precision': 0.9868598742746577, 'recall': 0.9867226509305492, 'f1-score': 0.9867235465756515, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 1\n",
      "[{'pos': {'precision': 0.9803173327977506, 'recall': 0.9854917796365734, 'f1-score': 0.9828977460696461, 'support': 34670}, 'neg': {'precision': 0.9858882280327685, 'recall': 0.9808524297317666, 'f1-score': 0.9833638818541788, 'support': 35827}, 'accuracy': 0.9831340340723719, 'macro avg': {'precision': 0.9831027804152596, 'recall': 0.9831721046841699, 'f1-score': 0.9831308139619124, 'support': 70497}, 'weighted avg': {'precision': 0.9831484953094176, 'recall': 0.9831340340723719, 'f1-score': 0.9831346390828588, 'support': 70497}}, {'pos': {'precision': 0.9830654916191464, 'recall': 0.9845683463613026, 'f1-score': 0.9838163450591576, 'support': 34669}, 'neg': {'precision': 0.9850450047520546, 'recall': 0.9835877969129427, 'f1-score': 0.984315861510314, 'support': 35827}, 'accuracy': 0.9840700181570585, 'macro avg': {'precision': 0.9840552481856004, 'recall': 0.9840780716371227, 'f1-score': 0.9840661032847358, 'support': 70496}, 'weighted avg': {'precision': 0.9840715063861217, 'recall': 0.9840700181570585, 'f1-score': 0.9840702059292151, 'support': 70496}}, {'pos': {'precision': 0.9787343508832105, 'recall': 0.9876835213014509, 'f1-score': 0.9831885722489414, 'support': 34669}, 'neg': {'precision': 0.9879752182483807, 'recall': 0.9792335389510705, 'f1-score': 0.983584955913481, 'support': 35827}, 'accuracy': 0.9833891284611893, 'macro avg': {'precision': 0.9833547845657956, 'recall': 0.9834585301262606, 'f1-score': 0.9833867640812113, 'support': 70496}, 'weighted avg': {'precision': 0.9834306819529443, 'recall': 0.9833891284611893, 'f1-score': 0.9833900196721919, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 5 2\n",
      "[{'pos': {'precision': 0.9794545815715543, 'recall': 0.9955292760311508, 'f1-score': 0.9874265116079475, 'support': 34670}, 'neg': {'precision': 0.9956038345907312, 'recall': 0.9797917771513105, 'f1-score': 0.9876345220510656, 'support': 35827}, 'accuracy': 0.9875313843142262, 'macro avg': {'precision': 0.9875292080811428, 'recall': 0.9876605265912306, 'f1-score': 0.9875305168295065, 'support': 70497}, 'weighted avg': {'precision': 0.9876617292220651, 'recall': 0.9875313843142262, 'f1-score': 0.987532223767977, 'support': 70497}}, {'pos': {'precision': 0.9811766043959168, 'recall': 0.9953272375897776, 'f1-score': 0.9882012657865346, 'support': 34669}, 'neg': {'precision': 0.9954142723695757, 'recall': 0.9815223155720546, 'f1-score': 0.988419484498412, 'support': 35827}, 'accuracy': 0.9883113935542442, 'macro avg': {'precision': 0.9882954383827462, 'recall': 0.9884247765809161, 'f1-score': 0.9883103751424733, 'support': 70496}, 'weighted avg': {'precision': 0.9884123756523324, 'recall': 0.9883113935542442, 'f1-score': 0.9883121674233712, 'support': 70496}}, {'pos': {'precision': 0.9781555461113473, 'recall': 0.9958175892007268, 'f1-score': 0.9869075524555486, 'support': 34669}, 'neg': {'precision': 0.995880798840942, 'recall': 0.9784799173807464, 'f1-score': 0.9871036774229881, 'support': 35827}, 'accuracy': 0.9870063549704948, 'macro avg': {'precision': 0.9870181724761447, 'recall': 0.9871487532907366, 'f1-score': 0.9870056149392683, 'support': 70496}, 'weighted avg': {'precision': 0.987163754088299, 'recall': 0.9870063549704948, 'f1-score': 0.9870072257591184, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 1\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 1\n",
      "[{'pos': {'precision': 0.9807951772642457, 'recall': 0.9854629362561292, 'f1-score': 0.9831235162937918, 'support': 34670}, 'neg': {'precision': 0.9858673097414615, 'recall': 0.9813269322019705, 'f1-score': 0.9835918812684469, 'support': 35827}, 'accuracy': 0.9833609940848547, 'macro avg': {'precision': 0.9833312435028536, 'recall': 0.9833949342290499, 'f1-score': 0.9833576987811193, 'support': 70497}, 'weighted avg': {'precision': 0.9833728655383739, 'recall': 0.9833609940848547, 'f1-score': 0.983361542194851, 'support': 70497}}, {'pos': {'precision': 0.9828786832412523, 'recall': 0.9852317632467046, 'f1-score': 0.9840538165684736, 'support': 34669}, 'neg': {'precision': 0.9856759176365264, 'recall': 0.9833924135428588, 'f1-score': 0.984532841514021, 'support': 35827}, 'accuracy': 0.984296981389015, 'macro avg': {'precision': 0.9842773004388894, 'recall': 0.9843120883947817, 'f1-score': 0.9842933290412472, 'support': 70496}, 'weighted avg': {'precision': 0.9843002747738142, 'recall': 0.984296981389015, 'f1-score': 0.9842972633842381, 'support': 70496}}, {'pos': {'precision': 0.979076623636832, 'recall': 0.9866451296547348, 'f1-score': 0.9828463063529007, 'support': 34669}, 'neg': {'precision': 0.9869793863719453, 'recall': 0.9795963937812264, 'f1-score': 0.9832740313226684, 'support': 35827}, 'accuracy': 0.983062868815252, 'macro avg': {'precision': 0.9830280050043887, 'recall': 0.9831207617179807, 'f1-score': 0.9830601688377846, 'support': 70496}, 'weighted avg': {'precision': 0.9830929122278287, 'recall': 0.983062868815252, 'f1-score': 0.9830636818421747, 'support': 70496}}]\n",
      "Output file with 140992 samples saved at location: data_train\n",
      "Output file with 70497 samples saved at location: data_test\n",
      "40 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 2\n",
      "Output file with 140993 samples saved at location: data_train\n",
      "Output file with 70496 samples saved at location: data_test\n",
      "40 0.1 10 2\n",
      "[{'pos': {'precision': 0.9793741311317276, 'recall': 0.9956734929333718, 'f1-score': 0.9874565556302473, 'support': 34670}, 'neg': {'precision': 0.9957446808510638, 'recall': 0.9797080414212744, 'f1-score': 0.9876612687648606, 'support': 35827}, 'accuracy': 0.9875597543157865, 'macro avg': {'precision': 0.9875594059913957, 'recall': 0.9876907671773232, 'f1-score': 0.9875589121975539, 'support': 70497}, 'weighted avg': {'precision': 0.9876937430981184, 'recall': 0.9875597543157865, 'f1-score': 0.987560592078235, 'support': 70497}}, {'pos': {'precision': 0.9812340062553313, 'recall': 0.995413770227004, 'f1-score': 0.988273027964318, 'support': 34669}, 'neg': {'precision': 0.9954990658438544, 'recall': 0.9815781393920786, 'f1-score': 0.9884895928492122, 'support': 35827}, 'accuracy': 0.9883823195642306, 'macro avg': {'precision': 0.9883665360495928, 'recall': 0.9884959548095413, 'f1-score': 0.9883813104067651, 'support': 70496}, 'weighted avg': {'precision': 0.9884836982928655, 'recall': 0.9883823195642306, 'f1-score': 0.9883830891043983, 'support': 70496}}, {'pos': {'precision': 0.9776343355415889, 'recall': 0.9960483428999971, 'f1-score': 0.986755439985141, 'support': 34669}, 'neg': {'precision': 0.9961050776141468, 'recall': 0.9779495910905184, 'f1-score': 0.986943845861326, 'support': 35827}, 'accuracy': 0.9868503177485247, 'macro avg': {'precision': 0.9868697065778678, 'recall': 0.9869989669952577, 'f1-score': 0.9868496429232335, 'support': 70496}, 'weighted avg': {'precision': 0.987021411066917, 'recall': 0.9868503177485247, 'f1-score': 0.9868511903443965, 'support': 70496}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = train_supervised(input='data_train.txt',\n",
    "#     loss='softmax', minCount=5, dim=100, lr=0.15, ws=5, epoch = 40, wordNgrams=4, thread=4)\n",
    "\n",
    "model_results = pd.DataFrame()\n",
    "modelnum = 1\n",
    "\n",
    "for dim in params['dim']:\n",
    "    for param_loss in params['loss']:\n",
    "        for epoch in params['epoch']:\n",
    "            for lr in params['lr']:\n",
    "                for min_count in params['min_count']:\n",
    "                    for word_ngrams in params['word_ngrams']:\n",
    "                        kfold_metrics = []\n",
    "                        for fold in folds:\n",
    "                            train_df = fold[0]\n",
    "                            test_df = fold[1]\n",
    "                            to_ft_format(train_df['body'], train_df['label'], train_path)\n",
    "                            to_ft_format(test_df['body'], test_df['label'], test_path)\n",
    "                            print(epoch, lr, min_count, word_ngrams)\n",
    "                            model = train_supervised(input=train_path, loss=param_loss, minCount=min_count,  dim=dim, lr=lr, ws=5, epoch = epoch, wordNgrams=word_ngrams, thread=8)\n",
    "                            modelnum +=1\n",
    "                            \n",
    "                            test_X = cleaner(test_df['body'])\n",
    "                            predictions = [model.predict(doc)[0][0].replace(\"__label__\", \"\") for doc in test_X]\n",
    "                            \n",
    "                            result = metrics.classification_report(test_df['label'].astype(str), predictions, target_names=('pos', 'neg'), output_dict=True)\n",
    "                            kfold_metrics.append(result)\n",
    "                        print(kfold_metrics)\n",
    "#                         for label in types:\n",
    "#                         cross_precision = np.mean([elem[label]['precision'] for elem in kfold_metrics])\n",
    "#                         cross_recall = np.mean([elem[label]['recall'] for elem in kfold_metrics])\n",
    "                        cross_f1_score = np.mean([elem['macro avg']['f1-score'] for elem in kfold_metrics])\n",
    "                        current_model = pd.DataFrame([[\"model_num:\" + str(model) + 'epoch:' + str(epoch) + 'lr:' + str(lr)  + ' ,min_count:' + str(min_count) + ' ,word_ngrams:' + str(word_ngrams) + ' ,loss:' + str(param_loss) + ' ,dim:' + str(dim), cross_f1_score]], columns=['model', 'f1-score'])\n",
    "                        model_results = pd.concat([model_results, current_model])\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.987246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.984380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.983011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.982974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.982922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.982751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.982713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.982520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>model_num:&lt;fasttext.FastText._FastText object ...</td>\n",
       "      <td>0.982074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  f1-score\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987677\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987616\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987611\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987606\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987601\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987597\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987573\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987511\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987488\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987436\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987426\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987417\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987388\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987384\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987289\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.987246\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.984380\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983802\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983722\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983613\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983570\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983528\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983239\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983182\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983149\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.983011\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.982974\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.982922\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.982751\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.982713\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.982520\n",
       "0  model_num:<fasttext.FastText._FastText object ...  0.982074"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results.sort_values(by=['f1-score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, лучшая FastText модель дала нам f1-score 0.987677, а лучшая классическая модель -- 0.984594\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В дальнейшем можно будет попытаться улучшить модель на основе использования мета-параметров:\n",
    "* Количеста хештегов в сообщении\n",
    "* Времени постинга твита(утро-день-вечер-ночь)\n",
    "* Длины твита\n",
    "\n",
    "итд\n",
    "\n",
    "Также, можно будет попробовать дообучить BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
